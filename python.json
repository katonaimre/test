{
	// Place your snippets for python here. Each snippet is defined under a snippet name and has a prefix, body and 
	// description. The prefix is what is used to trigger the snippet and the body will be expanded and inserted. Possible variables are:
	// $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders. Placeholders with the 
	// same ids are connected.
	// Example:
	// "Print to console": {
	// 	"prefix": "log",
	// 	"body": [
	// 		"console.log('$1');",
	// 		"$2"
	// 	],
	// 	"description": "Log output to console"
	// }

	"alap":{
		"prefix": "alap",
		"body": [

			"#!/usr/bin/env python3"
			"",
			"",
			"def main():",
			"",
			"	print()",
			"",
			"if __name__ == '__main__':",
			"	main()"
			]
		},

		"keres": {
			"prefix": "keres",
			"body": [
			  "import sys",
			  "from seged import *",
			  "",
			  "",
			  "class Feladat:",
			  "",
			  "    def __init__(self, kezdő, cél=None):",
			  "        self.kezdő = kezdő",
			  "        self.cél = cél",
			  "",
			  "    def rákövetkező(self, állapot):",
			  "        raise NotImplementedError",
			  "",
			  "    def érték(self):",
			  "        raise NotImplementedError",
			  "",
			  "    def célteszt(self, állapot):",
			  "       #return állapot == self.cél",
			  "       raise NotImplementedError",
			  "",
			  "    def útköltség(self, c, állapot1, lépés, állapot2):",
			  "        return c + 1",
			  "",
			  "",
			  "class Csúcs:",
			  "",
			  "    def __init__(self, állapot, szülő=None, lépés=None, útköltség=0):",
			  "        self.állapot = állapot",
			  "        self.szülő = szülő",
			  "        self.lépés = lépés",
			  "        self.útköltség = útköltség",
			  "        if szülő:",
			  "            self.mélység = szülő.mélység + 1",
			  "        else:",
			  "            self.mélység = 0",
			  "",
			  "    def __repr__(self):",
			  "        return \"<Csúcs: %s>\" % (self.állapot, )",
			  "",
			  "        #return \"%s\" % (list(self.állapot),)",
			  "",
			  "    def út(self):",
			  "        x, válasz = self, [self]",
			  "        while x.szülő:",
			  "            válasz.append(x.szülő)",
			  "            x = x.szülő",
			  "        return válasz",
			  "",
			  "    def megoldás(self):",
			  "        utam = self.út()",
			  "        utam.reverse()",
			  "        return [csúcs.lépés for csúcs in utam[1:]]",
			  "",
			  "    def kiterjeszt(self, feladat):",
			  "        for (művelet, következő) in feladat.rákövetkező(self.állapot):",
			  "            if következő not in [csúcs.állapot for csúcs in self.út()]:",
			  "                yield Csúcs(következő, self, művelet,",
			  "                            feladat.útköltség(self.útköltség, self.állapot, művelet,                                              következő))",
			  "",
			  "def fakereső(feladat, perem):",
			  "    perem.append(Csúcs(feladat.kezdő))",
			  "    while perem:",
			  "        csúcs = perem.pop()",
			  "        if feladat.célteszt(csúcs.állapot):",
			  "            return  csúcs",
			  "        else:",
			  "            perem.extend(csúcs.kiterjeszt(feladat))",
			  "",
			  "    return None",
			  "",
			  "",
			  "def szélességi_fakeresés(feladat):",
			  "    return fakereső(feladat, Sor())",
			  "",
			  "def mélységi_fakeresés(feladat):",
			  "    return fakereső(feladat,Verem())",
			  "",
			  "",
			  "def gráfkereső(feladat, perem):",
			  "    perem.append(Csúcs(feladat.kezdő))",
			  "    kifejtési_sor = set()",
			  "    while perem:",
			  "        csúcs = perem.pop()",
			  "        if feladat.célteszt(csúcs.állapot):",
			  "            return csúcs",
			  "        if csúcs.állapot not in kifejtési_sor:",
			  "            kifejtési_sor.add(csúcs.állapot)",
			  "            perem.extend(csúcs.kiterjeszt(feladat))",
			  "",
			  "    return None",
			  "",
			  "",
			  "def szélességi_gráfkereső(feladat):",
			  "",
			  "    return  gráfkereső(feladat, Sor())",
			  "",
			  "def mélységi_gráfkereső(feladat):",
			  "",
			  "    return gráfkereső(feladat, Verem())",
			  "",
			  "",
			  "def best_first(feladat, f):",
			  "    return gráfkereső(feladat, RendezettLista(f))",
			  "",
			  "",
			  "def a_csillag(feladat, h):",
			  "    def f(n):",
			  "        return n.útköltség + h(n)",
			  "",
			  "    return best_first(feladat,f)",
			  "",
			  "",
			  "",
			  ""
			],
			"description": "keres"
		  },

		  "seged": {
			"prefix": "seged",
			"body": [
			  "",
			  "import bisect",
			  "import random",
			  "import functools",
			  "",
			  "class Várólista:",
			  "    def __init__(self):",
			  "        pass",
			  "    def extend(self, elemek):",
			  "        for elem in elemek: self.append(elem)",
			  "",
			  "",
			  "def Verem():",
			  "    return []",
			  "",
			  "",
			  "class Sor(Várólista):",
			  "    def __init__(self):",
			  "        self.A = []; self.kezd = 0",
			  "    def append(self, elem):",
			  "        self.A.append(elem)",
			  "    def __len__(self):",
			  "        return len(self.A) - self.kezd",
			  "    def extend(self, elemek):",
			  "        self.A.extend(elemek)",
			  "        ",
			  "    def pop(self):",
			  "        e = self.A[self.kezd]",
			  "        self.kezd += 1",
			  "        if self.kezd > 5 and self.kezd > len(self.A)/2:",
			  "            self.A = self.A[self.kezd:]",
			  "            self.kezd = 0",
			  "        return e",
			  "    ",
			  "",
			  "",
			  "class RLElem:",
			  "    def __init__(self,érték,elem):",
			  "        self.értékem = érték",
			  "        self.elemem = elem",
			  "    def __lt__(self,másik):",
			  "        return self.értékem < másik.értékem",
			  "    def érték(self):",
			  "        return self.értékem",
			  "    def elem(self):",
			  "        return self.elemem",
			  "",
			  "class RendezettLista(Várólista):",
			  "    def __init__(self, f):",
			  "        self.A=[]",
			  "        self.f=f",
			  "    def append(self, elem):",
			  "        pár = RLElem(self.f(elem),elem)",
			  "        bisect.insort(self.A, pár)",
			  "    def __len__(self):",
			  "        return len(self.A)",
			  "    def pop(self):",
			  "            return self.A.pop(0).elem()",
			  "",
			  "",
			  "def argmin(lista, fv):",
			  "    legjobb = lista[0]; legjobb_érték = fv(legjobb)",
			  "    for x in lista[1:]:",
			  "        x_érték = fv(x)",
			  "        if x_érték < legjobb_érték:",
			  "            legjobb, legjobb_érték = x, x_érték",
			  "    return legjobb",
			  "",
			  ""
			],
			"description": "seged"
		  },

		  "fakereso": {
			"prefix": "fakereso",
			"body": [
			  "def fakereső(feladat, perem):",
			  "    perem.append(Csúcs(feladat.kezdő))",
			  "    while perem:",
			  "        csúcs = perem.pop()",
			  "        if feladat.célteszt(csúcs.állapot):",
			  "            return  csúcs",
			  "        else:",
			  "            perem.extend(csúcs.kiterjeszt(feladat))",
			  "",
			  "    return None",
			  "",
			  "",
			  "def szélességi_fakeresés(feladat):",
			  "    return fakereső(feladat, Sor())",
			  "",
			  "def mélységi_fakeresés(feladat):",
			  "    return fakereső(feladat,Verem())",
			  ""
			],
			"description": "fakereso"
		  },

		  "grafkereso": {
			"prefix": "grafkereso",
			"body": [
			  "def gráfkereső(feladat, perem):",
			  "    perem.append(Csúcs(feladat.kezdő))",
			  "    kifejtési_sor = set()",
			  "    while perem:",
			  "        csúcs = perem.pop()",
			  "        if feladat.célteszt(csúcs.állapot):",
			  "            return csúcs",
			  "        if csúcs.állapot not in kifejtési_sor:",
			  "            kifejtési_sor.add(csúcs.állapot)",
			  "            perem.extend(csúcs.kiterjeszt(feladat))",
			  "",
			  "    return None",
			  "",
			  "",
			  "def szélességi_gráfkereső(feladat):",
			  "",
			  "    return  gráfkereső(feladat, Sor())",
			  "",
			  "def mélységi_gráfkereső(feladat):",
			  "",
			  "    return gráfkereső(feladat, Verem())",
			  ""
			],
			"description": "grafkereso"
		  },

		  "best_first": {
			"prefix": "best_first",
			"body": [
			  "def best_first(feladat, f):",
			  "    return gráfkereső(feladat, RendezettLista(f))",
			  ""
			],
			"description": "best_first"
		  },

		  "a_csillag": {
			"prefix": "a_csillag",
			"body": [
			  "def a_csillag(feladat, h):",
			  "    def f(n):",
			  "        return n.útköltség + h(n)",
			  "",
			  "    return best_first(feladat,f)",
			  ""
			],
			"description": "a_csillag"
		  },

		  "3_kancso": {
			"prefix": "3_kancso",
			"body": [
			  "from keres import Feladat, szélességi_fakereső, mélységi_fakereső, best_first",
			  "",
			  "",
			  "class kancso_promlema(Feladat):",
			  "    def __init__(self, ke,c):",
			  "        self.kezdő = ke",
			  "        self.cél = c",
			  "        self.MAX1 = 3",
			  "        self.MAX2 = 5",
			  "        self.MAX3 = 8",
			  "",
			  "    def célteszt(self, a): # a -> állapot",
			  "        return a[0] ==self.cél or a[1] ==self.cél or a[2] ==self.cél",
			  "",
			  "    def rákövetkező(self, a):",
			  "        a1,a2,a3 = a",
			  "        gyerekek =  []",
			  "",
			  "        if a1!=0 and a2 != self.MAX2:",
			  "            T= min(a1,self.MAX2-a2)",
			  "            uj_allapot =(a1-T, a2+T,a3)",
			  "            gyerekek.append((\"1-ből 2-be\", uj_allapot))",
			  "",
			  "        if a1!=0 and a3 != self.MAX3:",
			  "            T= min(a1,self.MAX3-a3)",
			  "            uj_allapot =(a1-T, a2,a3+T)",
			  "            gyerekek.append((\"1-ből 3-ba\", uj_allapot))",
			  "",
			  "        if a2!=0 and a1 != self.MAX1:",
			  "            T= min(a2,self.MAX1-a1)",
			  "            uj_allapot =(a1+T, a2-T,a3)",
			  "            gyerekek.append((\"2-ből 1-be\", uj_allapot))",
			  "",
			  "        if a2!=0 and a3 != self.MAX3:",
			  "            T= min(a2,self.MAX3-a3)",
			  "            uj_allapot =(a1, a2-T,a3+T)",
			  "            gyerekek.append((\"2-ből 1-be\", uj_allapot))",
			  "",
			  "        if a3!=0 and a1 != self.MAX1:",
			  "            T= min(a3,self.MAX1-a1)",
			  "            uj_allapot =(a1+T, a2,a3-T)",
			  "            gyerekek.append((\"3-ből 1-be\", uj_allapot))",
			  "",
			  "        if a3 != 0 and a2 != self.MAX2:",
			  "            T = min(a3, self.MAX2 - a2)",
			  "            uj_allapot = (a1 , a2+T, a3 - T)",
			  "            gyerekek.append((\"3-ből 2-be\", uj_allapot))",
			  "",
			  "",
			  "        return gyerekek",
			  "",
			  "",
			  "def heurisztika(csúcs):",
			  "    a = csúcs.állapot",
			  "",
			  "    return  min ([abs(a[0]-4),abs(a[1]-4), abs(a[2]-4)])",
			  "",
			  "",
			  "",
			  "if __name__ == \"__main__\":",
			  "    kancso = kancso_promlema((0,0,8),4)",
			  "    #csúcs = szélességi_fakereső(kancso)",
			  "    #csúcs = mélységi_fakereső(kancso)",
			  "    csúcs = best_first(kancso, heurisztika)",
			  "    út= csúcs.út()",
			  "    út.reverse()",
			  "    print(út)",
			  "    print(csúcs.megoldás())",
			  "",
			  ""
			],
			"description": "3_kancso"
		  },

	"TicTacToe": {
		"prefix": "Tictactoe",
		"body": [
		  "from ast import literal_eval as make_tuple",
		  "import random",
		  "",
		  "",
		  "# KIEGESZITO FUGGVENYEK/OSZTALYOK",
		  "def update(x, **entries):",
		  "    \"\"\"Asszociatív tömb, struct értékeinek frissítése.\"\"\"",
		  "    if isinstance(x, dict):",
		  "        x.update(entries)",
		  "    else:",
		  "        x.__dict__.update(entries)",
		  "    return x",
		  "",
		  "",
		  "def cmp(a, b):",
		  "    return (a > b) - (a < b)",
		  "",
		  "",
		  "def if_(test, result, alternative):",
		  "    \"\"\"Háromágú értékadás.\"\"\"",
		  "    if test:",
		  "        if callable(result):",
		  "            return result()",
		  "        return result",
		  "    else:",
		  "        if callable(alternative):",
		  "            return alternative()",
		  "        return alternative",
		  "",
		  "",
		  "class Struct:",
		  "    \"\"\"Pehelykönnyű osztály, metódusok nélkül.\"\"\"",
		  "",
		  "    def __init__(self, **entries):",
		  "        \"\"\"Megadott attribútumok rögzítese.\"\"\"",
		  "        self.__dict__.update(entries)",
		  "",
		  "    def __repr__(self):",
		  "        \"\"\"Megjeleníti a struktúrát.\"\"\"",
		  "        args = ['%s=%s' % (k, repr(v)) for (k, v) in vars(self).items()]",
		  "        return 'Struct(%s)' % ', '.join(args)",
		  "",
		  "",
		  "def jatssz(jatek, *jatekosok):",
		  "    \"\"\"n személyes, felváltva lépő játékmenet.\"\"\"",
		  "    allapot = jatek.kezdo",
		  "    jatek.kiir(allapot)",
		  "    while True:",
		  "        for jatekos in jatekosok:",
		  "            lepes = jatekos(jatek, allapot)",
		  "            allapot = jatek.lep(lepes, allapot)",
		  "            jatek.kiir(allapot)",
		  "            if jatek.levele(allapot):",
		  "                return jatek.hasznossag(allapot, jatekosok[0])",
		  "",
		  "",
		  "def num_or_str(x):",
		  "    \"\"\"Lehetőség szerint számmá alakít.\"\"\"",
		  "    try:",
		  "        return int(x)",
		  "    except ValueError:",
		  "        try:",
		  "            return float(x)",
		  "        except ValueError:",
		  "            return str(x).strip()",
		  "",
		  "",
		  "# KERESESEK",
		  "# Minimax keresés",
		  "def minimax(allapot, jatek):",
		  "    \"\"\"Legjobb lépés meghatározása teljes kereséssel.\"\"\"",
		  "    jatekos = jatek.kovetkezik(allapot)",
		  "",
		  "    # definiáljuk a keresési fa egyes szintjein használatos címkézést.",
		  "    def max_ertek(allapot):",
		  "        if jatek.levele(allapot):",
		  "            return jatek.hasznossag(allapot, jatekos)",
		  "        return max([min_ertek(s) for (_, s) in jatek.rakovetkezo(allapot)])",
		  "",
		  "    def min_ertek(allapot):",
		  "        if jatek.levele(allapot):",
		  "            return jatek.hasznossag(allapot, jatekos)",
		  "        return min([max_ertek(s) for (_, s) in jatek.rakovetkezo(allapot)])",
		  "",
		  "    # minimax lényege",
		  "    fiai_ertekei = [(a, min_ertek(s)) for (a, s) in jatek.rakovetkezo(allapot)]",
		  "    lepes, ertek = max(fiai_ertekei, key=lambda a_s: a_s[1])",
		  "    return lepes",
		  "",
		  "",
		  "def alfabeta_kereses(allapot, jatek, d=4, levagas_teszt=None, kiertekel=None):",
		  "    \"\"\"A játékfa keresése adott mélységig.\"\"\"",
		  "    jatekos = jatek.kovetkezik(allapot)",
		  "",
		  "    def max_ertek(allapot, alfa, beta, melyseg):",
		  "        if levagas_teszt(allapot, melyseg):",
		  "            return kiertekel(allapot)",
		  "        v = float(\"-inf\")",
		  "        for (a, s) in jatek.rakovetkezo(allapot):",
		  "            v = max(v, min_ertek(s, alfa, beta, melyseg+1))",
		  "            if v >= beta:",
		  "                return v",
		  "            alfa = max(alfa, v)",
		  "        return v",
		  "",
		  "    def min_ertek(allapot, alfa, beta, melyseg):",
		  "        if levagas_teszt(allapot, melyseg):",
		  "            return kiertekel(allapot)",
		  "        v = float(\"inf\")",
		  "        for (a, s) in jatek.rakovetkezo(allapot):",
		  "            v = min(v, max_ertek(s, alfa, beta, melyseg+1))",
		  "            if v <= alfa:",
		  "                return v",
		  "            beta = min(beta, v)",
		  "        return v",
		  "",
		  "    # Alfabéta keresés",
		  "    levagas_teszt = levagas_teszt or \\",
		  "        (lambda allapot, melyseg: melyseg > d or jatek.levele(allapot))",
		  "    kiertekel = kiertekel or \\",
		  "        (lambda allapot: jatek.hasznossag(allapot, jatekos))",
		  "    alfa = float(\"-inf\")",
		  "    legjobb_lepes = None",
		  "    for a, s in jatek.rakovetkezo(allapot):",
		  "        v = min_ertek(s, alfa, float(\"inf\"), 0)",
		  "        if v > alfa:",
		  "            alfa = v",
		  "            legjobb_lepes = a",
		  "    return legjobb_lepes",
		  "",
		  "",
		  "# JATEKOSOK",
		  "# Játékosok típusai",
		  "def kerdez_jatekos(jatek, allapot):",
		  "    \"\"\"Felhasználói input.\"\"\"",
		  "    return num_or_str(input('Mit lép? '))",
		  "",
		  "",
		  "def random_jatekos(jatek, allapot):",
		  "    \"\"\"Véletlen választ a lehetőségek közül.\"\"\"",
		  "    return random.choice(jatek.legalis_lepesek(allapot))",
		  "",
		  "",
		  "def alfabeta_jatekos(jatek, allapot):",
		  "    \"\"\"Játékfában keres.\"\"\"",
		  "    return alfabeta_kereses(allapot, jatek)",
		  "",
		  "",
		  "def minimax_jatekos(jatek, allapot):",
		  "    \"\"\"Játékfában keres.\"\"\"",
		  "    return minimax(allapot, jatek)",
		  "",
		  "",
		  "# JATEK ALAPOSZTALY",
		  "class Jatek:",
		  "    \"\"\"Absztrakt osztály a játékok megadására.\"\"\"",
		  "",
		  "    def legalis_lepesek(self, allapot):",
		  "        \"\"\"Adott állapotban megtehető lépések listája.\"\"\"",
		  "        raise NotImplementedError()",
		  "",
		  "    def lep(self, lepes, allapot):  # NOQA",
		  "        \"\"\"Aktuális állapotban megtett lépés eredménye.\"\"\"",
		  "        raise NotImplementedError",
		  "",
		  "    def hasznossag(self, allapot, jatekos):",
		  "        \"\"\"A játékos számára ekkora haszna volt (nyereség/veszteség).\"\"\"",
		  "        raise NotImplementedError()",
		  "",
		  "    def levele(self, allapot):",
		  "        \"\"\"A játékfa terminális csúcsa az állapot.\"\"\"",
		  "        return not self.legalis_lepesek(allapot)",
		  "",
		  "    def kovetkezik(self, allapot):",
		  "        \"\"\"Soron következő játékos meghatározása.\"\"\"",
		  "        return allapot.kovetkezik",
		  "",
		  "    def kiir(self, allapot):",
		  "        \"\"\"Az állás megmutatása.\"\"\"",
		  "        print(allapot)",
		  "",
		  "    def rakovetkezo(self, allapot):",
		  "        \"\"\"Rákövetkező (lépés, állapot) párok listája.\"\"\"",
		  "        return [(lepes, self.lep(lepes, allapot))",
		  "                for lepes in self.legalis_lepesek(allapot)]",
		  "",
		  "    def __repr__(self):",
		  "        \"\"\"Játék nevének kiírása.\"\"\"",
		  "        return '<%s>' % self.__class__.__name__",
		  "",
		  "",
		  "# TIC-TAC TOE OSZTALY",
		  "class TicTacToe(Jatek):",
		  "    \"\"\"Általánosított 3x3-as amőba.\"\"\"",
		  "",
		  "    def __init__(self, h=3, v=3, k=3):",
		  "        \"\"\"Játék alapstrukturájának kialakítása.\"\"\"",
		  "        update(self, h=h, v=v, k=k)",
		  "        lepesek = [(x, y) for x in range(1, h+1) for y in range(1, v+1)]",
		  "        self.kezdo = Struct(",
		  "            kovetkezik='X', eredmeny=0, tabla={}, lepesek=lepesek)",
		  "",
		  "    def legalis_lepesek(self, allapot):",
		  "        \"\"\"Minden üres mező lehetséges lépést jelent.\"\"\"",
		  "        return allapot.lepesek",
		  "",
		  "    def lep(self, lepes, allapot):",
		  "        \"\"\"Lépés hatása.\"\"\"",
		  "        if type(lepes) is str:",
		  "            lepes = make_tuple(lepes)",
		  "        if lepes not in allapot.lepesek:",
		  "            return allapot  # téves lépés volt",
		  "        tabla = allapot.tabla.copy()",
		  "        tabla[lepes] = allapot.kovetkezik",
		  "        lepesek = list(allapot.lepesek)",
		  "        lepesek.remove(lepes)",
		  "        return Struct(",
		  "            kovetkezik=if_(allapot.kovetkezik == 'X', 'O', 'X'),",
		  "            eredmeny=self.ertekel(tabla, lepes, allapot.kovetkezik),",
		  "            tabla=tabla, lepesek=lepesek)",
		  "",
		  "    def hasznossag(self, allapot, jatekos):",
		  "        \"\"\"X értékelése: 1, ha nyer; -1, ha veszít, 0 döntetlenért.\"\"\"",
		  "        return if_(jatekos == \"X\", allapot.eredmeny, -allapot.eredmeny)",
		  "",
		  "    def levele(self, allapot):",
		  "        \"\"\"A nyert állás vagy a tele tábla a játék végét jelenti.\"\"\"",
		  "        return allapot.eredmeny != 0 or len(allapot.lepesek) == 0",
		  "",
		  "    def kiir(self, allapot):",
		  "        \"\"\"Lássuk az aktuális állást.\"\"\"",
		  "        tabla = allapot.tabla",
		  "        for x in range(1, self.h+1):",
		  "            for y in range(1, self.v+1):",
		  "                print(tabla.get((x, y), '.'), end=\" \")",
		  "            print()",
		  "        print(allapot.eredmeny)",
		  "        print()",
		  "",
		  "    def ertekel(self, tabla, lepes, jatekos):",
		  "        \"\"\"Ha X nyer ezzel a lépéssel, akkor 1, ha O, akkor -1, különben 0.\"\"\"",
		  "        if (self.k_egy_sorban(tabla, lepes, jatekos, (0, 1)) or",
		  "                self.k_egy_sorban(tabla, lepes, jatekos, (1, 0)) or",
		  "                self.k_egy_sorban(tabla, lepes, jatekos, (1, -1)) or",
		  "                self.k_egy_sorban(tabla, lepes, jatekos, (1, 1))):",
		  "            return if_(jatekos == 'X', +1, -1)",
		  "        else:",
		  "            return 0",
		  "",
		  "    def k_egy_sorban(self, tabla, lepes, jatekos, irany):",
		  "        \"\"\"Igaz, ha van a lépéstől adott irányba k azonos figura.\"\"\"",
		  "        delta_x, delta_y = irany",
		  "        x, y = lepes",
		  "        n = 0",
		  "        while tabla.get((x, y)) == jatekos:",
		  "            n += 1",
		  "            x, y = x + delta_x, y + delta_y",
		  "        x, y = lepes",
		  "        while tabla.get((x, y)) == jatekos:",
		  "            n += 1",
		  "            x, y = x - delta_x, y - delta_y",
		  "        n -= 1   # lépés duplán számolva",
		  "        return n >= self.k",
		  "",
		  "",
		  "def main():",
		  "    tto = TicTacToe()",
		  "",
		  "    # Ket random jatekos egymas ellen",
		  "    # jatssz(tto, random_jatekos, random_jatekos)",
		  "",
		  "    # X -> minimax_jatekos 0 -> random_jatekos",
		  "    jatssz(tto, minimax_jatekos, random_jatekos)",
		  "",
		  "    # X -> random_jatekos 0 -> minimax_jatekos",
		  "    # jatssz(tto, random_jatekos, minimax_jatekos)",
		  "",
		  "    # X -> minimax_jatekos 0 -> minimax_jatekos",
		  "    # jatssz(tto, minimax_jatekos, minimax_jatekos)",
		  "",
		  "    # X -> random_jatekos 0 -> alfabeta_jatekos",
		  "    # jatssz(tto, random_jatekos, alfabeta_jatekos)",
		  "",
		  "    # X -> alfabeta_jatekos 0 -> random_jatekos",
		  "    # jatssz(tto, alfabeta_jatekos, random_jatekos)",
		  "",
		  "    # X -> alfabeta_jatekos 0 -> alfabeta_jatekos",
		  "    # jatssz(tto, alfabeta_jatekos, alfabeta_jatekos)",
		  "",
		  "",
		  "if __name__ == '__main__':",
		  "    main()",
		  ""
		],
		"description": "TicTacToe"
	  },

	  "Hanoi": {
		"prefix": "Hanoi",
		"body": [
		  "from keres import *",
		  "",
		  "class Hanoi_problema(Feladat):",
		  "    def __init__(self, ke,c):",
		  "        self.cél = c",
		  "        self.kezdő = ke",
		  "",
		  "    def célteszt(self, allapot):",
		  "        return allapot ==  self.cél",
		  "",
		  "",
		  "    def rákövetkező(self, allapot):",
		  "        gyerekek = []",
		  "",
		  "        for melyiket in range(0,3):",
		  "            for hova in ['P', 'Q','R']:",
		  "                alkalmazhato = True",
		  "                if allapot[melyiket] != hova:",
		  "                    for i in range(0,melyiket):",
		  "                        if allapot[i] != allapot[melyiket] and allapot[i]!=hova:",
		  "                            alkalmazhato = True",
		  "                        else:",
		  "                            alkalmazhato= False",
		  "                            break",
		  "                else:",
		  "                    alkalmazhato = False",
		  "",
		  "                if alkalmazhato:",
		  "                    tmp = list(allapot)",
		  "                    tmp[melyiket] = hova",
		  "                    uj_allapot = tuple(tmp)",
		  "                    gyerekek.append((f\"{melyiket+1}->{hova}\",uj_allapot))",
		  "",
		  "",
		  "        return gyerekek",
		  "",
		  "def heurisztika(csúcs):",
		  "    # Ez a heurisztikus függvény minden csúcs állapotára megmondja, hány lépés szükséges még a célállapothoz",
		  "    a = csúcs.állapot",
		  "    # Megszámolja, hogy hány korong van még nem a céloszlopon.",
		  "    n = sum(1 for x in a if x != 'R')",
		  "    return 2 ** n -1",
		  "",
		  "if __name__ == \"__main__\":",
		  "    h = Hanoi_problema(('P','P','P'),('R','R','R'))",
		  "    # csúcs = szélességi_fakereső(kancso)",
		  "    csúcs = mélységi_fakereső(h)",
		  "    út = csúcs.út()",
		  "    út.reverse()",
		  "    print(út)",
		  "    print(csúcs.megoldás())"
		],
		"description": "Hanoi"
	  },

	  "N_kiralyno": {
		"prefix": "N_kiralyno",
		"body": [
		  "from keres import *",
		  "",
		  "class n_kiralyno_problema(Feladat):",
		  "    def __init__(self,k,c):",
		  "        self.kezdő = k",
		  "        self.cél  = c",
		  "        self.N = len(k) -1",
		  "",
		  "    def célteszt(self,a):",
		  "        return a[self.N]  == self.cél",
		  "",
		  "    def rákövetkező(self,a):",
		  "        gyereke = []",
		  "        s= a[self.N]",
		  "",
		  "        for j in range(0,self.N):",
		  "            alkalmazhato = True",
		  "            for m in range(0,s):",
		  "                if a[m] != j and abs(m-s) != abs(a[m]-j):",
		  "                    #alkalmazhato = True",
		  "                    pass",
		  "                else:",
		  "                    alkalmazhato = False",
		  "                    break",
		  "",
		  "            if alkalmazhato:",
		  "                tmp = list(a)",
		  "                tmp[s] = j",
		  "                tmp[self.N] = s+1",
		  "                uj_allapot = tuple(tmp)",
		  "                gyereke.append((str(s)+\" -> \"+str(j),uj_allapot))",
		  "",
		  "        return gyereke",
		  "",
		  "",
		  "def heurisztika(csúcs):",
		  "    # Ez a heurisztika megmondja, hogy hány pár királynő üti egymást.",
		  "    # Minél kisebb a szám, annál közelebb vagy a megoldáshoz.",
		  "    # A csúcs állapotában a[-1] jelzi az éppen elhelyezett királynő számát ",
		  "    # (azaz csak részleges állapotod van), ",
		  "    # akkor az aktuális részmegoldás alapján csak az eddig elhelyezett királynőket kell vizsgálni",
		  "    a = csúcs.állapot",
		  "    N = len(a) - 1",
		  "    s = a[-1]",
		  "    ütközések = 0",
		  "    for i in range(0, s):",
		  "        for j in range(i+1, s):",
		  "            if a[i] == a[j]:",
		  "                ütközések += 1",
		  "            if abs(i - j) == abs(a[i] - a[j]):",
		  "                ütközések += 1",
		  "    return ütközések",
		  "",
		  "",
		  "",
		  "",
		  "",
		  "",
		  "",
		  "if __name__ == \"__main__\":",
		  "    h = n_kiralyno_problema((-1,-1,-1,-1,-1,-1,-1,-1,0),8)",
		  "    #csúcs = szélességi_fakeresés(h)",
		  "    #csúcs = mélységi_fakeresés(h)",
		  "    csúcs = best_first(h, heurisztika)",
		  "    megoldas = csúcs.út()",
		  "    megoldas.reverse()",
		  "    print(megoldas)",
		  "    print(csúcs.megoldás())"
		],
		"description": "N_kiralyno"
	  },


	  "navi_bayes_iris": {
		"prefix": "naiv_bayes_iris",
		"body": [
		  "# Naiv Bayes osztályozó példa - Iris adathalmazon",
		  "from sklearn import datasets",
		  "from sklearn.model_selection import train_test_split",
		  "from sklearn.naive_bayes import GaussianNB",
		  "from sklearn.metrics import classification_report, confusion_matrix",
		  "import matplotlib.pyplot as plt",
		  "",
		  "# 1. Adatok betöltése",
		  "iris = datasets.load_iris()",
		  "X = iris.data",
		  "y = iris.target",
		  "",
		  "# 2. Tanító- és tesztadatok szétválasztása",
		  "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)",
		  "",
		  "# 3. Modell létrehozása",
		  "model = GaussianNB()",
		  "",
		  "# 4. Modell betanítása",
		  "model.fit(X_train, y_train)",
		  "",
		  "# 5. Predikció a teszt adatokon",
		  "y_pred = model.predict(X_test)",
		  "",
		  "# 6. Eredmények kiértékelése",
		  "print(\"Confusion Matrix:\")",
		  "print(confusion_matrix(y_test, y_pred))",
		  "",
		  "print(\"\\nClassification Report:\")",
		  "print(classification_report(y_test, y_pred))",
		  "",
		  "",
		  "plt.figure(figsize=(8,6))",
		  "for i, color in zip(range(3), ['red', 'blue', 'green']):",
		  "    plt.scatter(X_test[y_test == i, 0], X_test[y_test == i, 1],",
		  "                color=color, label=iris.target_names[i])",
		  "plt.xlabel('Sepal length')",
		  "plt.ylabel('Sepal width')",
		  "plt.title('Iris tesztadatok - Valós osztályok')",
		  "plt.legend()",
		  "plt.grid(True)",
		  "plt.show()",
		  ""
		],
		"description": "navi_bayes_iris"
	  },

	  "navi_bayes_2": {
		"prefix": "naiv_bayes_2",
		"body": [
		  "import streamlit as st",
		  "from sklearn.feature_extraction.text import CountVectorizer",
		  "from sklearn.naive_bayes import MultinomialNB",
		  "",
		  "# 1. Egyszerű tanító adathalmaz",
		  "texts = [",
		  "    'Free money now!!!',",
		  "    'Hi Mom, how are you?',",
		  "    'Win a million dollars today!',",
		  "    'Reminder: Meeting at 10am tomorrow.',",
		  "    'You have been selected for a prize!',",
		  "    'Can we have lunch tomorrow?',",
		  "    'Congratulations, you are a winner!',",
		  "    'Hey, are you coming to the party?'",
		  "]",
		  "labels = [1, 0, 1, 0, 1, 0, 1, 0]  # 1 = Spam, 0 = Ham",
		  "",
		  "# 2. Szöveg vektorizálás és modell tanítása",
		  "vectorizer = CountVectorizer()",
		  "X = vectorizer.fit_transform(texts)",
		  "model = MultinomialNB()",
		  "model.fit(X, labels)",
		  "",
		  "# 3. Streamlit app",
		  "st.title('Spam vagy Ham? - Naiv Bayes osztályozó')",
		  "",
		  "user_input = st.text_input('Írj be egy üzenetet:')",
		  "",
		  "if user_input:",
		  "    input_vector = vectorizer.transform([user_input])",
		  "    prediction = model.predict(input_vector)[0]",
		  "",
		  "    if prediction == 1:",
		  "        st.error('Ez valószínűleg SPAM üzenet!')",
		  "    else:",
		  "        st.success('Ez egy normális (HAM) üzenet.')",
		  ""
		],
		"description": "navi_bayes_2"
	  },

	  "game_search_alg": {
		"prefix": "game_search_alg",
		"body": [
		  "import numpy as np",
		  "import random",
		  "",
		  "",
		  "# SEARCHES",
		  "# Minimax search",
		  "def minimax_search(state, game):",
		  "    player = game.next(state)",
		  "",
		  "    # define labels on each level of the tree",
		  "    def max_value(state):",
		  "        if game.is_leaf(state):",
		  "            return game.goodness(state, player)",
		  "        return max([min_value(s) for (_, s) in game.next_state(state)])",
		  "",
		  "    def min_value(state):",
		  "        if game.is_leaf(state):",
		  "            return game.goodness(state, player)",
		  "        return min([max_value(s) for (_, s) in game.next_state(state)])",
		  "",
		  "    # minimax method",
		  "    children_values = [(a, min_value(s)) for (a, s) in game.next_state(state)]",
		  "    step, value = max(children_values, key=lambda a_s: a_s[1])",
		  "    return step",
		  "",
		  "",
		  "def alfabeta_search(state, game, d=4, cut_test=None, expand=None):",
		  "    \"\"\"Search game tree until defined depth\"\"\"",
		  "    player = game.next(state)",
		  "",
		  "    def max_value(state, alfa, beta, depth):",
		  "        if cut_test(state, depth):",
		  "            return expand(state)",
		  "        v = float(\"-inf\")",
		  "        for (a, s) in game.next_state(state):",
		  "            v = max(v, min_value(s, alfa, beta, depth+1))",
		  "            if v >= beta:",
		  "                return v",
		  "            alfa = max(alfa, v)",
		  "        return v",
		  "",
		  "    def min_value(state, alfa, beta, depth):",
		  "        if cut_test(state, depth):",
		  "            return expand(state)",
		  "        v = float(\"inf\")",
		  "        for (a, s) in game.next_state(state):",
		  "            v = min(v, max_value(s, alfa, beta, depth+1))",
		  "            if v <= alfa:",
		  "                return v",
		  "            beta = min(beta, v)",
		  "        return v",
		  "",
		  "    # Alfabeta search",
		  "    cut_test = cut_test or (lambda state, depth: depth > d or game.is_leaf(state))",
		  "    expand = expand or (lambda state: game.goodness(state, player))",
		  "    alfa = float(\"-inf\")",
		  "    best_step = None",
		  "    for a, s in game.next_state(state):",
		  "        v = min_value(s, alfa, float(\"inf\"), 0)",
		  "        if v > alfa:",
		  "            alfa = v",
		  "            best_step = a",
		  "    return best_step",
		  "",
		  "",
		  "class QLearningAgent:",
		  "    def __init__(self, n_states, n_actions, learning_rate):",
		  "        self.n_states = n_states",
		  "        self.n_actions = n_actions",
		  "        self.learning_rate = learning_rate",
		  "        ",
		  "        self.q_table = np.zeros((n_states, n_actions))",
		  "    ",
		  "    def act(self, state, epsilon):",
		  "        # Generate a random number on the [0, 1) interval",
		  "        random_int = random.uniform(0, 1)",
		  "        ",
		  "        # We exploit with (1-epsilon) probability",
		  "        if random_int > epsilon:",
		  "            action = np.argmax(self.q_table[state])",
		  "        # We explore with epsilon probability",
		  "        else:",
		  "            action = random.randint(0, self.n_actions - 1)",
		  "        ",
		  "        return action",
		  "    ",
		  "    def learn(self, state, action, reward, new_state, gamma):",
		  "        old_value = self.q_table[state][action]",
		  "        new_estimate = reward + gamma * max(self.q_table[new_state]) ",
		  "        ",
		  "        self.q_table[state][action] = old_value + self.learning_rate * (new_estimate - old_value)",
		  ""
		],
		"description": "game_search_alg"
	  },

	  "tictactoe_q_learning": {
		"prefix": "tictactoe_q_learning",
		"body": [
		  "import matplotlib.pyplot as plt",
		  "import random",
		  "from game_search_algorithms import alfabeta_search, minimax_search, QLearningAgent",
		  "import numpy as np",
		  "import json",
		  "from tqdm import tqdm",
		  "import pickle",
		  "",
		  "",
		  "class Game:",
		  "    def legal_steps(self, state):",
		  "        \"\"\"Steps that can be made in given state.\"\"\"",
		  "        raise NotImplementedError()",
		  "",
		  "    def take_step(self, step, state):  # NOQA",
		  "        \"\"\"Result of taking step in given state.\"\"\"",
		  "        raise NotImplementedError",
		  "",
		  "    def goodness(self, state, player):",
		  "        \"\"\"Goodness measure of the state for the player.\"\"\"",
		  "        raise NotImplementedError()",
		  "",
		  "    def is_leaf(self, state):",
		  "        \"\"\"Is the node a terminal node.\"\"\"",
		  "        return not self.legal_steps(state)",
		  "",
		  "    def next(self, state):",
		  "        \"\"\"Return next player.\"\"\"",
		  "        return state['next']",
		  "",
		  "    def print(self, state):",
		  "        \"\"\"Print current state.\"\"\"",
		  "        print(state)",
		  "",
		  "    def next_state(self, state):",
		  "        \"\"\"Return next (step, state) list.\"\"\"",
		  "        return [(step, self.take_step(step, state))",
		  "                for step in self.legal_steps(state)]",
		  "",
		  "    def __repr__(self):",
		  "        \"\"\"Print the name of the game.\"\"\"",
		  "        return '<%s>' % self.__class__.__name__",
		  "",
		  "",
		  "# TIC-TAC TOE CLASS",
		  "class TicTacToe(Game):",
		  "    \"\"\"3x3 version.\"\"\"",
		  "",
		  "    def __init__(self, h=3, v=3, k=3):",
		  "        \"\"\"Base of the game\"\"\"",
		  "        self.h = 3",
		  "        self.v = 3",
		  "        self.k = 3",
		  "        steps = [(x, y) for x in range(1, h + 1) for y in range(1, v + 1)]",
		  "        self.initial = {'next': 'X',",
		  "                        'result': 0,",
		  "                        'board': {},",
		  "                        'steps': steps}",
		  "",
		  "    def legal_steps(self, state):",
		  "        \"\"\"We can step on every empty cell\"\"\"",
		  "        return state['steps']",
		  "",
		  "    def take_step(self, step, state):",
		  "        \"\"\"Effect of the step\"\"\"",
		  "        if step not in state['steps']:",
		  "            return state",
		  "        board = state['board'].copy()",
		  "        board[step] = state['next']",
		  "        steps = list(state['steps'])",
		  "        steps.remove(step)",
		  "        return {",
		  "            'next': 'X' if state['next'] == 'O' else 'O',",
		  "            # need to change",
		  "            'result': self.result(board, step, state['next']),",
		  "            'board': board,",
		  "            'steps': steps",
		  "        }",
		  "",
		  "    def result(self, board, step, player):",
		  "        \"\"\"If X wins with this step then return 1. If O wins with this then return -1. Else return 0.\"\"\"",
		  "        if (self.check_triples(board, step, player, (0, 1)) or self.check_triples(board, step, player, (1, 0)) or",
		  "                self.check_triples(board, step, player, (1, -1)) or self.check_triples(board, step, player, (1, 1))):",
		  "            return 1 if player == 'X' else -1",
		  "        return 0",
		  "",
		  "    def check_triples(self, board, step, player, direction):",
		  "        \"\"\"Check for triples in a direction.\"\"\"",
		  "        delta_x, delta_y = direction",
		  "        x, y = step",
		  "        n = 0",
		  "        while board.get((x, y)) == player:",
		  "            n += 1",
		  "            x, y = x + delta_x, y + delta_y",
		  "        x, y = step",
		  "        while board.get((x, y)) == player:",
		  "            n += 1",
		  "            x, y = x - delta_x, y - delta_y",
		  "        n -= 1",
		  "        return n >= self.k",
		  "",
		  "    def goodness(self, state, player):",
		  "        \"\"\"X goodness: 1, if it wins; -1, if it loses, 0 if draw.\"\"\"",
		  "        return state['result'] if player == \"X\" else -state['result']",
		  "",
		  "    def is_leaf(self, state):",
		  "        \"\"\"If someone won or the table is full it will be the end of the game.\"\"\"",
		  "        return state['result'] != 0 or len(state['steps']) == 0",
		  "",
		  "    def print(self, state):",
		  "        \"\"\"Let's see the current state.\"\"\"",
		  "        board = state['board']",
		  "        for x in range(1, self.h + 1):",
		  "            for y in range(1, self.v + 1):",
		  "                print(board.get((x, y), '.'), end=\" \")",
		  "            print()",
		  "        print('Result of the game: ', state['result'])",
		  "        print()",
		  "",
		  "",
		  "# PLAYERS",
		  "def random_player(game, state):",
		  "    \"\"\"Randomly choose between options\"\"\"",
		  "    return random.choice(game.legal_steps(state))",
		  "",
		  "",
		  "def alfabeta_player(game, state):",
		  "    \"\"\"Search in game tree\"\"\"",
		  "    return alfabeta_search(state, game)",
		  "",
		  "",
		  "def minimax_player(game, state):",
		  "    \"\"\"Search in game tree\"\"\"",
		  "    return minimax_search(state, game)",
		  "",
		  "",
		  "def play_game(game, *players):",
		  "    state = game.initial",
		  "    # game.print(state)",
		  "    while True:",
		  "        for player in players:",
		  "            step = player(game, state)",
		  "            state = game.take_step(step, state)",
		  "            # game.print(state)",
		  "            if game.is_leaf(state):",
		  "                end_result = game.goodness(state, 'X')",
		  "                return \"X wins\" if end_result == 1 else \"O wins\" if end_result == -1 else \"Draw\"",
		  "",
		  "",
		  "# We instantiate our Q-learning agent",
		  "agent = QLearningAgent(n_states=19683, n_actions=9, learning_rate=0.01)",
		  "",
		  "# We define the necessary variables: the environment, the number of steps that the agent can take in a given",
		  "# episode and the states that we have encountered so far",
		  "tto = TicTacToe()",
		  "N_MAX_STEPS_PER_EPISODE = 9",
		  "state_to_id = {}",
		  "",
		  "",
		  "# We encode the given state to a string that we can use for deciding whether if we have encountered",
		  "# this state before or not",
		  "def state_to_str(state):",
		  "    result = [[\" \", \" \", \" \"] for r in range(3)]",
		  "    for k, v in state[\"board\"].items():",
		  "        result[k[0] - 1][k[1] - 1] = v",
		  "    return \"\\n\".join([\"|\".join(r) for r in result])",
		  "",
		  "",
		  "def encountered_state(state, memory):",
		  "    return state in memory",
		  "",
		  "",
		  "def play_episodes(n_episodes, max_epsilon=1.0, min_epsilon=0.05, decay_rate=0.0001, gamma=0.9, learn=True, enemy=None):",
		  "    global state_to_id",
		  "    global tto",
		  "    global agent",
		  "    ",
		  "    rewards = []",
		  "    epsilon_history = []",
		  "",
		  "    # We go over each episode",
		  "    for episode in tqdm(range(n_episodes)):",
		  "        done = False",
		  "",
		  "        # We decrease the epsilon and reset the variables",
		  "        epsilon = min_epsilon + (max_epsilon - min_epsilon) * \\",
		  "            np.exp(-decay_rate * episode)",
		  "            ",
		  "        total_reward = 0",
		  "",
		  "        # We reset the environment to the starting state & store it",
		  "        state = tto.initial",
		  "        state_representation = state_to_str(state)",
		  "        if state_representation not in state_to_id:",
		  "            state_to_id[state_representation] = len(state_to_id)",
		  "",
		  "        while not done:",
		  "            ##########################",
		  "            # Q-learning agent's turn",
		  "            # We ask our agent for an action",
		  "            action = agent.act(",
		  "                state=state_to_id[state_representation], epsilon=epsilon)",
		  "",
		  "            # Since our action is just an integer, we transform it into a tuple",
		  "            action_tuple = ((action // 3) + 1, (action % 3) + 1)",
		  "",
		  "            # We take the action that the agent signaled & store its representation",
		  "            new_state = tto.take_step(state=state, step=action_tuple)",
		  "            state_representation = state_to_str(state)",
		  "            new_state_representation = state_to_str(new_state)",
		  "",
		  "            # If the game has ended, we get the reward depending on the end results",
		  "            if tto.is_leaf(new_state):",
		  "                reward = tto.goodness(new_state, 'X')",
		  "                done = True",
		  "            # If the agent picked a cell that is already occupied, then we terminate the episode",
		  "            elif new_state_representation == state_representation:",
		  "                reward = -1",
		  "                done = True",
		  "            # Otherwise the reward of being in any other state is 0",
		  "            else:",
		  "                reward = 0",
		  "",
		  "            # We check if the states we encountered have been stored or not",
		  "            if state_representation not in state_to_id:",
		  "                state_to_id[state_representation] = len(state_to_id)",
		  "            if new_state_representation not in state_to_id:",
		  "                state_to_id[new_state_representation] = len(state_to_id)",
		  "",
		  "            # We update our Q-table and update our total reward for the episode",
		  "            if learn:",
		  "                agent.learn(state_to_id[state_representation], action,",
		  "                                reward, state_to_id[new_state_representation], gamma)",
		  "            total_reward += reward",
		  "",
		  "            # Our state is the new state",
		  "            state = new_state",
		  "",
		  "            # If done, finish the episode",
		  "            if done:",
		  "                break",
		  "            ",
		  "            ##########################",
		  "            # The enemy's turn",
		  "            step = enemy(tto, state)",
		  "            state = tto.take_step(step, state)",
		  "",
		  "            # If the enemy managed to arrive at a terminal state",
		  "            if tto.is_leaf(state):",
		  "                # We evaluate how good the state is for our agent and update its Q-table",
		  "                reward = tto.goodness(state, \"X\")",
		  "                total_reward += reward",
		  "",
		  "                agent.learn(state_to_id[state_representation], action,",
		  "                                reward, state_to_id[new_state_representation], gamma)",
		  "                ",
		  "                state_representation = state_to_str(state)",
		  "                ",
		  "                break",
		  "",
		  "            # We store the new state",
		  "            state_representation = state_to_str(state)",
		  "            if state_representation not in state_to_id:",
		  "                state_to_id[state_representation] = len(state_to_id)",
		  "",
		  "        # if not learn and total_reward < 0:",
		  "        #     print(state_representation)",
		  "        #     print(\"Total reward:\", total_reward)",
		  "",
		  "        rewards.append(total_reward)",
		  "        epsilon_history.append(epsilon)",
		  "",
		  "    return rewards, epsilon_history",
		  "",
		  "# TRAINING AND TESTING",
		  "# We define some parameters like the number of episodes, gamma, etc.",
		  "N_EPISODES = 500_000",
		  "max_epsilon = 1.0",
		  "min_epsilon = 0.05",
		  "decay_rate = 0.0001",
		  "gamma = 0.9",
		  "",
		  "# We train the agent",
		  "rewards, epsilon_history = play_episodes(n_episodes=N_EPISODES, max_epsilon=max_epsilon,",
		  "                                         min_epsilon=min_epsilon, decay_rate=decay_rate, gamma=gamma, learn=True, enemy=random_player)",
		  "",
		  "# Summary statistics",
		  "print('Statistics from training (vs. random player)')",
		  "print(\"Wins:\\t\", len([r for r in rewards if r > 0]))",
		  "print(\"Ties:\\t\", len([r for r in rewards if r == 0]))",
		  "print(\"Losses:\\t\", len([r for r in rewards if r < 0]))",
		  "",
		  "",
		  "# We smoother the results as the training history can greatly oscillate due to the random nature of the agent",
		  "def smoothen(data):",
		  "    return np.cumsum(data) / np.arange(len(rewards) + 1)[1:]",
		  "",
		  "",
		  "# We show how epsilon decreased throughout the training process",
		  "plt.plot(range(N_EPISODES), epsilon_history)",
		  "plt.title(\"The value of epsilon in each episode\")",
		  "plt.xlabel(\"Episode\")",
		  "plt.ylabel(\"Epsilon\")",
		  "plt.show()",
		  "",
		  "# We can check the rewards",
		  "plt.plot(rewards, \"*\")",
		  "plt.plot(smoothen(rewards))",
		  "plt.show()",
		  "",
		  "# Now we can evaluate how the trained agent performs against a random agent",
		  "rewards, epsilon_history = play_episodes(",
		  "    n_episodes=10_000, max_epsilon=0, min_epsilon=0, decay_rate=0, gamma=0, learn=False, enemy=random_player)",
		  "",
		  "# Summary statistics",
		  "print('Evaluation vs. random player')",
		  "print(\"Wins:\\t\", len([r for r in rewards if r > 0]))",
		  "print(\"Ties:\\t\", len([r for r in rewards if r == 0]))",
		  "print(\"Losses:\\t\", len([r for r in rewards if r < 0]))",
		  "",
		  "# We can check the rewards as well",
		  "plt.plot(rewards, \"*\")",
		  "plt.plot(smoothen(rewards))",
		  "plt.show()",
		  "",
		  "# Now we can save the agent",
		  "with open(\"agent.pkl\", \"wb\") as f:",
		  "    pickle.dump(agent, f)",
		  "with open(\"state_to_id.pkl\", \"wb\") as f:",
		  "    pickle.dump(state_to_id, f)",
		  "",
		  "# PLAY AGAINST TRAINED AGENT",
		  "# # load agent",
		  "# agent_f = open(\"agent.pkl\", \"rb\")",
		  "# agent = pickle.load(agent_f)",
		  "# state_to_id_f = open(\"state_to_id.pkl\", \"rb\")",
		  "# state_to_id = pickle.load(state_to_id_f)",
		  "#",
		  "# # And now we can play against the agent",
		  "# done = False",
		  "# state = tto.initial",
		  "# state_representation = state_to_str(state)",
		  "# total_reward = 0",
		  "#",
		  "# if state_representation not in state_to_id:",
		  "#     state_to_id[state_representation] = len(state_to_id)",
		  "#",
		  "# while not done:",
		  "#     # Q-learning agent's turn",
		  "#     action = agent.act(",
		  "#         state=state_to_id[state_representation], epsilon=0)",
		  "#",
		  "#     action_tuple = ((action // 3) + 1, (action % 3) + 1)",
		  "#     new_state = tto.take_step(state=state, step=action_tuple)",
		  "#     # print('new_state = ', new_state)",
		  "#     state_representation = state_to_str(state)",
		  "#     new_state_representation = state_to_str(new_state)",
		  "#",
		  "#     if tto.is_leaf(new_state):",
		  "#         reward = tto.goodness(new_state, 'X')",
		  "#         print(state_to_str(new_state))",
		  "#         print(\"Game over\")",
		  "#         done = True",
		  "#     elif new_state_representation == state_representation:",
		  "#         reward = -1",
		  "#         print(\"Game over (illegal step)\")",
		  "#         done = True",
		  "#     else:",
		  "#         reward = 0",
		  "#",
		  "#     if state_representation not in state_to_id:",
		  "#         state_to_id[state_representation] = len(state_to_id)",
		  "#     if new_state_representation not in state_to_id:",
		  "#         state_to_id[new_state_representation] = len(state_to_id)",
		  "#",
		  "#     total_reward += reward",
		  "#",
		  "#     state = new_state",
		  "#     state_representation = state_to_str(state)",
		  "#",
		  "#     if done:",
		  "#         break",
		  "#",
		  "#     # We show the current state to the player and ask for a position in the form of x-y",
		  "#     print(new_state_representation)",
		  "#     # print(state)",
		  "#     inp = input(\"Your choice: \").split(\"-\")",
		  "#     pos_x, pos_y = int(inp[0]), int(inp[1])",
		  "#     step = (pos_x, pos_y)",
		  "#     # print(step)",
		  "#",
		  "#     state = tto.take_step(step, state)",
		  "#     state_representation = state_to_str(state)",
		  "#     # print(state)",
		  "#     if state_representation not in state_to_id:",
		  "#         state_to_id[state_representation] = len(state_to_id)",
		  "#",
		  "#     # If the human player managed to get to a terminal state, then we display the results",
		  "#     if tto.is_leaf(state):",
		  "#         done = True",
		  "#         reward = tto.goodness(state, \"X\")",
		  "#",
		  "#         print(\"Game over. You won.\")",
		  "#",
		  "#         total_reward += reward",
		  "#         break",
		  "#",
		  "# print(\"Total reward:\", total_reward)",
		  "",
		  ""
		],
		"description": "tictactoe_q_learning"
	  },

	  "neuralis_halo_1": {
		"prefix": "neuralis_halo_1",
		"body": [
		  "#A klasszikus neurális hálózat működésének órai magyarázatához tartozó segédkód",
		  "#Használd a  network_architect.png képen lévő szituációt: jelen példa arra folyamatra épül",
		  "",
		  "input_vector = [1.66, 1.56]",
		  "weights_1 = [1.45, -0.66]",
		  "bias = [0.0]",
		  "",
		  "#1. mutassuk be, hogy keletkezik egy  neuron az első rejtett rétegbe: a bemeneti vektor szorozva a súly vektor",
		  "",
		  "first_indexes_mult = input_vector[0] * weights_1[0]",
		  "second_indexes_mult = input_vector[1] * weights_1[1]",
		  "dot_product_1 = first_indexes_mult + second_indexes_mult",
		  "",
		  "print(f\"The dot product is: {dot_product_1}\")",
		  "",
		  "#numpy könyvtárral még könnyebb a szorzat számítás:",
		  "import numpy as np",
		  "dot_product_1 = np.dot(input_vector, weights_1)",
		  "print(f\"The dot product is: {dot_product_1}\")",
		  "",
		  "",
		  "#A 0-1 közötti kiemenet előállításához szükség van egy nem lineráis transzformációra: pl a logisztikus függvény",
		  "",
		  "def sigmoid(x):",
		  "    return 1 / (1 + np.exp(-x))",
		  "",
		  "# A predikció előállítása: az első rejtett rétegbeli neuron esetén vesszük - a fent deifinált - lienáris transzformáciját",
		  "def make_prediction(input_vector, weights, bias):",
		  "    layer_1 = np.dot(input_vector, weights) + bias",
		  "    layer_2 = sigmoid(layer_1)",
		  "    return layer_2",
		  "",
		  "#",
		  "# Kipróbáljuk a predikciót az input vektorra",
		  "",
		  "prediction = make_prediction(input_vector, weights_1, bias)",
		  "",
		  "print(f\"The prediction result is: {prediction}\")",
		  "",
		  "",
		  "",
		  " # most egy másik input vektorra is megnézzük",
		  "input_vector = np.array([2, 1.5])",
		  "prediction = make_prediction(input_vector, weights_1, bias)",
		  "print(f\"The prediction result is: {prediction}\")",
		  "",
		  "",
		  "",
		  "# Vizsgáljuk meg a predikció jóságát: tegyük fel hogy a fenti [2, 1.5] input vektorhoz az elvárt predikció a: 0",
		  "target = 0",
		  "# nézzük meg az eltérést(hibát): \"négyzetes eltérés\" a prediktált érték és az elvárt érték között, láthatjuk, hogy jó nagy az eltérés, tehát nagy hibával prediktál a háló",
		  "",
		  "mse = np.square(prediction - target)",
		  "print(f\"Prediction: {prediction}; Error: {mse}\")",
		  "",
		  "",
		  "#Hogyan lehet a hibát minimalizálni? Gradiens süllyedés módszere: deriválás szerepe: szóbeli magyarázat",
		  "#Mivel a hiba függvényem jelen példában egy másodfokú függvény (x^2), a deriváltja 2*x",
		  "# használd a gradient_descent.png képet a magyarázathoz (derivált szerepe a szélsőértékek meghatározásásoz)",
		  "derivative = 2 * (prediction - target)",
		  "print(f\"The derivative is {derivative}\")",
		  "",
		  "# Frissítjük a súlyokat a derivált segítségéve, láthatjuk, hogy a hiba sokkal kissebb lett:",
		  "weights_1 = weights_1 - derivative",
		  "prediction = make_prediction(input_vector, weights_1, bias)",
		  "error = (prediction - target) ** 2",
		  "print(f\"Prediction: {prediction}; Error: {error}\")",
		  "",
		  "",
		  "#Tanítási folyamat, backpropagation: szóbeli magyarázat csak()",
		  "",
		  "",
		  ""
		],
		"description": "neuralis_halo_1"
	  },

	  "neuralis_halo_2": {
		"prefix": "neuralis_halo_2",
		"body": [
		  "",
		  "from numpy import loadtxt",
		  "from keras.models import Sequential",
		  "from keras.layers import Dense",
		  "# load the dataset",
		  "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')",
		  "# split into input (X) and output (y) variables",
		  "X = dataset[:,0:8]",
		  "y = dataset[:,8]",
		  "# define the keras model",
		  "model = Sequential()",
		  "model.add(Dense(12, input_dim=8, activation='relu'))",
		  "model.add(Dense(8, activation='relu'))",
		  "model.add(Dense(1, activation='sigmoid'))",
		  "# compile the keras model",
		  "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])",
		  "# fit the keras model on the dataset",
		  "model.fit(X, y, epochs=150, batch_size=10)",
		  "# evaluate the keras model",
		  "_, accuracy = model.evaluate(X, y)",
		  "print('Accuracy: %.2f' % (accuracy*100))"
		],
		"description": "neuralis_halo_2_keras"
	  },

	  "neuralis_halo_3_tensor": {
		"prefix": "neuralis_halo_3_tensor",
		"body": [
		  "import numpy as np",
		  "from tensorflow import keras",
		  "from tensorflow.keras import layers",
		  "from matplotlib import pyplot as plt",
		  "",
		  "# Model / data parameters",
		  "num_classes = 10",
		  "input_shape = (28, 28, 1)",
		  "",
		  "# the data, split between train and test sets",
		  "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()",
		  "",
		  "# Scale images to the [0, 1] range",
		  "x_train = x_train.astype(\"float32\") / 255",
		  "x_test = x_test.astype(\"float32\") / 255",
		  "# Make sure images have shape (28, 28, 1)",
		  "x_train = np.expand_dims(x_train, -1)",
		  "x_test = np.expand_dims(x_test, -1)",
		  "print(\"x_train shape:\", x_train.shape)",
		  "print(x_train.shape[0], \"train samples\")",
		  "print(x_test.shape[0], \"test samples\")",
		  "",
		  "",
		  "for i in range(9):",
		  "",
		  "	plt.subplot(330 + 1 + i)",
		  "",
		  "	plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))",
		  "# show the figure",
		  "plt.show()",
		  "",
		  "",
		  "# convert class vectors to binary class matrices",
		  "y_train = keras.utils.to_categorical(y_train, num_classes)",
		  "y_test = keras.utils.to_categorical(y_test, num_classes)",
		  "",
		  "model = keras.Sequential(",
		  "    [",
		  "        keras.Input(shape=input_shape),",
		  "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),",
		  "        layers.MaxPooling2D(pool_size=(2, 2)),",
		  "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),",
		  "        layers.MaxPooling2D(pool_size=(2, 2)),",
		  "        layers.Flatten(),",
		  "        layers.Dropout(0.5),",
		  "        layers.Dense(num_classes, activation=\"softmax\"),",
		  "    ]",
		  ")",
		  "",
		  "model.summary()",
		  "",
		  "batch_size = 128",
		  "epochs = 1",
		  "",
		  "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])",
		  "",
		  "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)",
		  "",
		  "",
		  "score = model.evaluate(x_test, y_test, verbose=0)",
		  "print(\"Test loss:\", score[0])",
		  "print(\"Test accuracy:\", score[1])",
		  "",
		  ""
		],
		"description": "neuralis_halo_3_tensor"
	  }


}
